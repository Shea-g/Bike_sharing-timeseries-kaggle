{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae4b691f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#FE\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#from sklearn.impute import SimpleImputer #no missing vals\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "#regressors\n",
    "from sklearn.linear_model import PoissonRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "# Cross validation \n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "# Scoring metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import plot_roc_curve, auc, roc_curve\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#https://www.kaggle.com/competitions/bike-sharing-demand/overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dab2b704",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('bike_time_features.csv', index_col=0, parse_dates=True)\n",
    "df_reg = df.drop(['count', 'casual'], axis=1)\n",
    "df_cas = df.drop(['count', 'registered'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c95b8e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "rg_train, rg_test = train_test_split(df_reg, test_size=0.3, random_state=12)\n",
    "cs_train, cs_test = train_test_split(df_cas, test_size=0.3, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "806aa2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_rg = rg_train.drop(columns=['registered'])\n",
    "Xtrain_cs = cs_train.drop(columns=['casual'])\n",
    "\n",
    "Xtest_rg = rg_test.drop(columns=['registered'])\n",
    "Xtest_cs = cs_test.drop(columns=['casual'])\n",
    "\n",
    "ytrain_rg = rg_train['registered']\n",
    "ytrain_cs = cs_train['casual']\n",
    "\n",
    "ytest_rg = rg_test['registered']\n",
    "ytest_cs = cs_test['casual']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202ce17c",
   "metadata": {},
   "source": [
    "Data now TTS (for registered and casual)- going to be doing analyses on the split data, since it looked promising compared to the data as a whole (casual trends differed in a visually significant way)- and compare to the analyses I have previously done on the entire data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294faaf5",
   "metadata": {},
   "source": [
    "# Regressor Testing function \n",
    "Originally architected in other file, for efficient testing (only have to adjust col transformer pipeline) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8437931",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Regressor_testing(Xtrain, ytrain, Xtest,ytest, Transformer, Model, model_name_str):\n",
    "    \n",
    "    '''\n",
    "    Function to easily implement different models and transformers for quick testing\n",
    "    Different transformers, datasets and models can be input to quickly get an overview of results\n",
    "    Transformers should be defined outside of func (poss with other func?)\n",
    "    '''\n",
    "    \n",
    "    model_output= []\n",
    "    \n",
    "    ytrainlog = np.log1p(ytrain)\n",
    "    ytestlog = np.log1p(ytest)\n",
    "    \n",
    "    pipeline = Pipeline([ ('trans', Transformer), ('model', Model) ])\n",
    "    pipeline.fit(Xtrain, ytrainlog)\n",
    "    ypred = pipeline.predict(Xtest)\n",
    "    \n",
    "    score_train = \"R2 train score of\" + model_name_str + 'is ' + str(pipeline.score(Xtrain, ytrainlog))\n",
    "    score_train_mo =pipeline.score(Xtrain, ytrainlog)\n",
    "    model_output.append(score_train_mo)\n",
    "    \n",
    "    score_test = \"R2 test score of\" + model_name_str + 'is ' + str(pipeline.score(Xtest, ytestlog))\n",
    "    score_test_mo = pipeline.score(Xtrain, ytrainlog)\n",
    "    model_output.append(score_test_mo)\n",
    "    \n",
    "    RMSE = \"RMSE of\"+ model_name_str + 'is ' +  str(np.sqrt(mean_squared_error(ytest, ypred))) \n",
    "    RMSE_mo = np.sqrt(mean_squared_error(ytest, ypred))\n",
    "    model_output.append(RMSE_mo)\n",
    "    \n",
    "    \n",
    "    RMSLE = \"RMSLE of\"+ model_name_str + 'is ' +  str(np.sqrt(mean_squared_log_error(ytest, ypred))) \n",
    "    RMSLE_mo = np.sqrt(mean_squared_log_error(ytest, ypred))\n",
    "    model_output.append(RMSLE_mo)\n",
    "    \n",
    "    \n",
    "    print(score_train, score_test, RMSE, RMSLE)\n",
    "    \n",
    "    return (model_output)  #use this to put into a func which puts it in a table?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3daf7b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regressor_output_table(df_output, model_output, model_name_str):\n",
    "    \n",
    "    '''\n",
    "    A function taking the defined regressors being tested, \n",
    "    which formats all of them into a dataframe \n",
    "    for readability and quick comparison\n",
    "    '''\n",
    "    \n",
    "    df_model = pd.DataFrame([model_output], index=[model_name_str], columns=['R2_train','R2_test','RMSE','RMSLE'])\n",
    "    df = pd.concat([df_output, df_model])\n",
    "    \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd29f317",
   "metadata": {},
   "source": [
    "### Pipeline Placeholders \n",
    "(can copy and paste for efficiency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69c285f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_scaler = Pipeline([\n",
    "            ('Scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "pipeline_ohe = Pipeline([\n",
    "            ('ohe', OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "#cols to keep the same and use in model\n",
    "#('pass', 'passthrough', [])\n",
    "\n",
    "#custom func\n",
    "#('', FunctionTransformer(), ['relevant_col'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abc1bd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
